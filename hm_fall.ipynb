{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction to Python Exercises\n",
    "\n",
    "Before you turn this problem in, make sure everything runs as expected. First, restart the kernel (in the menubar, select Kernel → Restart) and then run all cells (in the menubar, select Cell → Run All).  You can speak with others regarding the assignment but all work must be your own. \n",
    "\n",
    "\n",
    "### This is a 15 point assignment graded from answers to questions and automated tests that should be run at the bottom. Be sure to clearly label all of your answers and commit final tests at the end. If you attempt to fake passing the tests you will receive a 0 on the assignment and it will be considered an ethical violation. (Note, not all questions have tests).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NAME = \"Jason Kuruzovich\"\n",
    "COLLABORATORS = \"Alyssa Hacker\"  #You can speak with others regarding the assignment, but all typed work must be your own."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise - Seaborn\n",
    "**For the following if your get a different color in your graph, that is fine**.\n",
    "\n",
    "\n",
    "\n",
    "(1) Create the following figure using the Titanic dataset (included with Seaborn).  \n",
    "![](./fig/hm4-1.png)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#answer for #1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q1b_answer=\"\"\"\n",
    "Interpret the above graph here.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(2a) Create the following figure using the Titanic dataset (included with Seaborn). \n",
    "![](./fig/hm4-2.png)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#answer for #4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q2b_answer=\"\"\"\n",
    "Interpret the above graph here.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(5a) Create the following figure using the Titanic dataset (included with Seaborn). \n",
    "![](./fig/hm4-3.png)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#answer for number 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q3b_answer=\"\"\"\n",
    "Interpret the above graph here.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(4b) Create the following figure using the Titanic dataset (included with Seaborn). \n",
    "![](./fig/hm4-4.png)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#answer for number 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q6b_answer=\"\"\"\n",
    "Interpret the above graph here.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise-Beautiful Soup\n",
    "Imagine you would like to write a simple python script that pulls in data from https://webrobots.io/kickstarter-datasets/.  To do that, we would have to get all the links.  Here is some starter code that will download the url into a soup object. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This will pull the data\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "response = requests.get(\"https://webrobots.io/kickstarter-datasets/\")\n",
    "html_doc = response.text\n",
    "soup = BeautifulSoup(html_doc, 'html.parser')\n",
    "print(soup.prettify())\n",
    " \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (7) Describe where in the html the link tags occur.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q7_answer=\"\"\"\n",
    "put your answer here. \n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(8) Before we try to get the links, lets make sure we can parse the web page. Set the value of the variable `page_title` equal to the contents inside the <title> </title> tag.  The title tag should not be included. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Answer 8 here. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "(9) The code below will pull out the text for one of the links. Could you create a list called `newlist` that pulls in the link for all of the files. [Hint: use a for loop to process all of the links.]\n",
    "\n",
    "```\n",
    "import re #This is the regular expressions. \n",
    "links = re.findall('https://s3.amazonaws.com/weruns/forfun/Kickstarter.*\\.zip', html_doc) #This is the pattern we want\n",
    "x=links[0]  #here we are setting the value equal to the first link. \n",
    "print(x[117:208])  #Here we are parsing the string using the relevant position. \n",
    "\n",
    "```\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Answer 9 here. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regular Expressions\n",
    "\n",
    "Did you know you just used regular expressions? This is a useful way of parsing through string data. \n",
    "\n",
    "(10) There are a lot of things that we can do with regular expressions.  For the input `text`, please complete the following transformations. \n",
    "\n",
    "- Change `text` to lower case.\n",
    "- Remove all emails and substitute them with '--'\n",
    "- Remove all digits and replace with *. \n",
    "- Split the lines and put them into a list called `textlines`.\n",
    "\n",
    "The resulting list should be:\n",
    "```\n",
    "['the test score is ** with the email -- for mgmt*****.',\n",
    " 'the test score is ** with the email -- for mgmt*****.']\n",
    "```\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "text=\"\"\"The test score is 85 with the email john@rpi.edu for MGMT33223.\n",
    "The test score is 83 with the email jim@rpi.edu for MGMT33223.\n",
    "\"\"\"\n",
    "# Multiple steps\n",
    "#\n",
    "#\n",
    "#textlines="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This Loads a Testing Array \n",
    "- This runs tests against your b array.  If you complete the assingment correctly, you will pass the tests. \n",
    "- **If you attempt to fake passing the tests you will receive a 0 on the assignment and it will be considered an ethical violation.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install ipython_unittest \n",
    "#if you didn't install last time. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext ipython_unittest\n",
    "#this enables running tests."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%unittest_main\n",
    "class TestHm4(unittest.TestCase):\n",
    "    def test_soup1(self):\n",
    "        self.assertEqual(page_title, \"Kickstarter Datasets – Web Scraping Service\")\n",
    "    def test_soup2(self):\n",
    "        self.assertEqual(newlist[5][0:65], 'https://s3.amazonaws.com/weruns/forfun/Kickstarter/Kickstarter_20')\n",
    "    def test_regexpress(self):\n",
    "        self.assertEqual(textlines[0], 'the test score is ** with the email -- for mgmt*****.')\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
