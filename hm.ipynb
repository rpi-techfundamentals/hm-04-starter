{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "YRxEdhsZhrkG"
   },
   "source": [
    "## Homework 04 - Instructions\n",
    "\n",
    "![](https://github.com/rpi-techfundamentals/hm-01-starter/blob/master/notsaved.png?raw=1)\n",
    "\n",
    "**WARNING!!!  If you see this icon on the top of your COLAB sesssion, your work is not saved automatically.**\n",
    "\n",
    "\n",
    "**When you are working on homeworks, make sure that you save often. You may find it easier to save intermident copies in Google drive. If you save your working file in Google drive all changes will be saved as you work. MAKE SURE that your final version is saved to GitHub.** \n",
    "\n",
    "Before you turn this problem in, make sure everything runs as expected. First, restart the kernel (in the menubar, select Kernel → Restart) and then run all cells (in the menubar, select Cell → Run All).  You can speak with others regarding the assignment but all work must be your own. \n",
    "\n",
    "\n",
    "### This is a 30 point assignment graded from answers to questions and automated tests that should be run at the bottom. Be sure to clearly label all of your answers and commit final tests at the end.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "kt0h7WvWhrkK",
    "outputId": "9b4cd825-4611-4f59-fd98-54311b7f828e"
   },
   "outputs": [],
   "source": [
    "files = \"https://github.com/rpi-techfundamentals/hm-04-starter/raw/master/files.zip\" \n",
    "!rm -rf * && pip install git+https://github.com/data-8/Gofer-Grader && wget $files && unzip -o files.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Twitter Exercises\n",
    "Here we have a simple exercise we are going to do that involves the Twitter API. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0Y8RlqeBhrki"
   },
   "outputs": [],
   "source": [
    "#Run this. It initiates autograding. \n",
    "from client.api.notebook import Notebook\n",
    "ok = Notebook('lab.ok')\n",
    "_ = ok.auth(inline=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get config data\n",
    "!wget https://www.dropbox.com/s/ojjs2aj14gjuqjb/config.yaml "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 270
    },
    "colab_type": "code",
    "id": "RxzLDkc1cCcR",
    "outputId": "ec3cba05-b869-4701-e1c8-689b59837773"
   },
   "outputs": [],
   "source": [
    " !pip install twitter ruamel.yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 786
    },
    "colab_type": "code",
    "id": "CLLJj2aWWUH5",
    "outputId": "4ef5a938-a093-4ec8-a389-43d2b395323d"
   },
   "outputs": [],
   "source": [
    "#importing the twitter package & some other things we will use.  \n",
    "from  twitter import *\n",
    "import datetime, traceback \n",
    "import json\n",
    "import time\n",
    "import sys \n",
    "import ruamel.yaml #A .yaml file \n",
    "#This is your configuration file.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BILCWzonWhI8"
   },
   "outputs": [],
   "source": [
    "#Load the config file  \n",
    "twitter_yaml='config.yaml'\n",
    "with open(twitter_yaml, 'r') as yaml_t:\n",
    "    cf_t=ruamel.yaml.round_trip_load(yaml_t, preserve_quotes=True)\n",
    "\n",
    "#Create your twitter object. \n",
    "import twitlab\n",
    "#Create Twitter Object\n",
    "twitter= twitlab.create_twitter_auth(cf_t)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "NWC0YPjoXOW1"
   },
   "source": [
    "(t1) Access the twitter object to retrieve the 5 tweets that has a hashtag \"#mlanalyticsdojorocks\" attached to them. Save these tweets into a list called *statuses*.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 66
    },
    "colab_type": "code",
    "id": "MpZSW6TAZSs-",
    "outputId": "9664131c-508c-4029-efc5-9e435f53e14f"
   },
   "outputs": [],
   "source": [
    "#Answer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "T9OzSaQjZU06"
   },
   "source": [
    "(t2) Now create a function `get_hashtags(tweets, hashtag)` that accepts a list of tweets and a hashtag and returns a list of *other* hashtags included in the tweets *except* `hashtag`. This means, you should not include the origional hashtag used (i.e.,  mlanalyticsdojorocks) and the function should aggregate hashtags across all tweets passed.  \n",
    "\n",
    "For example, if there is a a single tweet passed that says \"Hello world! #mlanalyticsdojorocks #learningmachinelearning\"  it would return ['#learningmachinelearning']\n",
    "\n",
    "Use your function and the `statuses` list to create `other_hashtags` as shown below: \n",
    "\n",
    "```\n",
    "other_hashtags= get_hashtags(statuses, '#mlanalyticsdojorocks')\n",
    "print(other_hashtags)\n",
    "\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Answer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise - Seaborn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dvKqATXthrkd"
   },
   "outputs": [],
   "source": [
    "#Import and load some libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import stats, integrate\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "titanic = sns.load_dataset(\"titanic\")\n",
    "import grading_object_detection as god"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "sKw1DGi3hrkm"
   },
   "source": [
    "\n",
    "(S1) Create the following figure using the Titanic dataset (included with Seaborn). Output the file to hm4-1.png in the current directory.  \n",
    "![](https://github.com/rpi-techfundamentals/hm-04-starter/raw/master/fig/hm4-1.png)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 324
    },
    "colab_type": "code",
    "id": "yR9pQbiOhrko",
    "outputId": "38724c5c-9a61-4737-f17e-bd939cd4fb95"
   },
   "outputs": [],
   "source": [
    "#Answer\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "id": "qY3sKzN5hrkw",
    "outputId": "e673f201-ccfe-4910-bbc9-aa7bb2ccf051"
   },
   "outputs": [],
   "source": [
    "#Test\n",
    "_ = ok.grade('q01')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "sKSRVPObhrkz"
   },
   "source": [
    "(S2) Create the following figure using the Titanic dataset (included with Seaborn). Output the plot to hm4-2.png in the current directory.  \n",
    "![](https://github.com/rpi-techfundamentals/hm-04-starter/raw/master/fig/hm4-2.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 324
    },
    "colab_type": "code",
    "id": "uifBYKMyhrk3",
    "outputId": "8cac3d12-a3e6-4f6d-8b60-d41c172e10d3"
   },
   "outputs": [],
   "source": [
    "#Answer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "id": "vsaHa89Khrk-",
    "outputId": "be89b2ec-56f8-4e8b-e3c4-1c1fc2618dee"
   },
   "outputs": [],
   "source": [
    "#Test\n",
    "_ = ok.grade('q02')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "jUP8uWPahrlB"
   },
   "source": [
    "(S3) Create the following figure using the Titanic dataset (included with Seaborn). Output the plot to hm4-3.png in the current directory.  \n",
    "![](https://github.com/rpi-techfundamentals/hm-04-starter/raw/master/fig/hm4-3.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 304
    },
    "colab_type": "code",
    "id": "KwTkdQ3shrlC",
    "outputId": "aec1875d-12b0-456e-c9b7-d6776e65e95b"
   },
   "outputs": [],
   "source": [
    "#Answer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "id": "_HV7_SQQhrlG",
    "outputId": "1392326e-cbba-4a35-e164-a5a7185867d5"
   },
   "outputs": [],
   "source": [
    "_ = ok.grade('q03')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1FVi0j13hrlO"
   },
   "outputs": [],
   "source": [
    "#Please provide an interpretation for the graph provided in question 3. \n",
    "\n",
    "man4=\"\"\"\n",
    "\n",
    "\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "l5msY87NhrlT"
   },
   "source": [
    "(S5) Create the following figure using the Titanic dataset (included with Seaborn). Output the plot to hm4-5.png in the current directory.  \n",
    "![](https://github.com/rpi-techfundamentals/hm-04-starter/raw/master/fig/hm4-5.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 324
    },
    "colab_type": "code",
    "id": "l9epWWpnhrlU",
    "outputId": "b3a4741a-945d-40f4-c983-544c3cd5ea2e"
   },
   "outputs": [],
   "source": [
    "#Answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "id": "r2IxIUJehrlW",
    "outputId": "d75117ad-fc59-4c28-ff28-712a0d190b11"
   },
   "outputs": [],
   "source": [
    "_ = ok.grade('q05')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "o4ZXQ7mLhrlY"
   },
   "source": [
    "## Exercise-Beautiful Soup\n",
    "Imagine you would like to write a simple python script that pulls in data from https://webrobots.io/kickstarter-datasets/.   \n",
    "\n",
    "First go to the above website.\n",
    "\n",
    "![](https://github.com/rpi-techfundamentals/hm-04-starter/raw/master/fig/crawler.png)\n",
    "\n",
    "\n",
    "To do that, we would have to get all the links.  Here is some starter code that will download the url into a soup object.\n",
    "\n",
    "```\n",
    "#This will pull the data\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "response = requests.get(\"https://webrobots.io/kickstarter-datasets/\")\n",
    "html_doc = response.text\n",
    "soup = BeautifulSoup(html_doc, 'html.parser')\n",
    "print(soup.prettify())\n",
    " \n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "ldhs0HrfhrlY",
    "outputId": "65013ca6-7967-4b59-f680-dfe388cbc2c2"
   },
   "outputs": [],
   "source": [
    "#This will pull the data\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "response = requests.get(\"https://webrobots.io/kickstarter-datasets/\")\n",
    "html_doc = response.text\n",
    "soup = BeautifulSoup(html_doc, 'html.parser')\n",
    "print(soup.prettify())\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7VC0CnFVhrlc"
   },
   "source": [
    "(bs1) Look through the html and find the links to the files that we want.  Set the variable `file_url` to be equal to the url of the files that we want to get"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Krc-H7rxhrld"
   },
   "outputs": [],
   "source": [
    "#update base url up to but not including the first /\n",
    "file_url= \"https://**************\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "id": "VDSEWiVohrlg",
    "outputId": "401397f3-b63a-4467-be31-ae7ecd6fbeba"
   },
   "outputs": [],
   "source": [
    "_ = ok.grade('bs1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "BcjfQ-07hrli"
   },
   "source": [
    "(bs2) Before we try to get the links, lets make sure we can parse the web page. Set the value of the variable `page_title` equal to the contents inside the page `<title>` tag. The variable `page_title` should not include the title tag (i.e., the `<title>`). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "g_jdtn2_hrli"
   },
   "outputs": [],
   "source": [
    "#answer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "id": "g34V5kgChrlk",
    "outputId": "0bee6a05-5373-4097-ffb1-bdca0b0ed39d"
   },
   "outputs": [],
   "source": [
    "_ = ok.grade('bs2')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7hr9a5_6hrln"
   },
   "source": [
    "(bs3) We talked about both regular expressions and beautiful soup.  Here is an example of how you could combine them to match a pattern. \n",
    "\n",
    "\n",
    "```\n",
    "import re\n",
    "soup.find(\"a\", href=re.compile(file_url), href=True)\n",
    "```\n",
    "\n",
    "Further process the data so that you get a list equal to all of the links to the json files `json_links` and a list equal to all the csv files `csv_links`.  \n",
    "\n",
    "![](https://github.com/rpi-techfundamentals/hm-04-starter/raw/master/fig/links.png)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 326
    },
    "colab_type": "code",
    "id": "L6og90cBhrlo",
    "outputId": "49b34e97-7c7b-4887-ef1e-b10a72e25a53"
   },
   "outputs": [],
   "source": [
    "#Answer \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "id": "dNE5iUvthrlr",
    "outputId": "48a47f95-d906-44a9-ceea-30787d5eacac"
   },
   "outputs": [],
   "source": [
    "_ = ok.grade('bs3')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "vgLdbR9Zhrls"
   },
   "source": [
    "### Regular Expressions\n",
    "\n",
    "Regular expressions is a useful way of parsing through string data. \n",
    "\n",
    "(RE1) Please complete a function `blind_text` that accepts a text string and does the the following transformations. \n",
    "\n",
    "- Change `text` to lower case.\n",
    "- Remove all emails and substitute them with '--'\n",
    "- Remove all digits and replace with *. \n",
    "- Split the lines and put them into a list called `textlines`.\n",
    "\n",
    "Given the text string:\n",
    "\n",
    "```\n",
    "my_text=\"\"\"The test score is 85 with the email john@rpi.edu for MGMT33223.\n",
    "The test score is 83 with the email jim@rpi.edu for MGMT33223.\"\"\"\n",
    "```\n",
    "\n",
    "The resulting list should be:\n",
    "```\n",
    "['the test score is ** with the email -- for mgmt*****.',\n",
    " 'the test score is ** with the email -- for mgmt*****.']\n",
    "```\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 56
    },
    "colab_type": "code",
    "id": "di4OPlZUhrlt",
    "outputId": "b5311da2-24f0-44f0-983c-f56679dfb1ab"
   },
   "outputs": [],
   "source": [
    "my_text=\"\"\"The test score is 85 with the email john@rpi.edu for MGMT33223.\n",
    "The test score is 83 with the email jim@rpi.edu for MGMT33223.\"\"\"\n",
    "\n",
    "#Create your function here. \n",
    "\n",
    "#Call the function\n",
    "result = blind_text(my_text)\n",
    "print(result)  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "id": "neSzaGBuhrlx",
    "outputId": "23a271a8-5918-4f5e-dd4c-dbb3857c20ae"
   },
   "outputs": [],
   "source": [
    "#Tests\n",
    "_ = ok.grade('re1')"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "colab": {
   "include_colab_link": true,
   "name": "hm.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
